{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Loading datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Loading datasetst as `pandas DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"/root/train.csv\", on_bad_lines='warn')\n",
        "test_df = pd.read_csv(\"/root/test.csv\")\n",
        "test_labels_df = pd.read_csv(\"/root/test_labels.csv\")\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Class distribution visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# List of labels for classification\n",
        "labels = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
        "       'insult', 'identity_hate']\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "train_df[labels].sum().sort_values().plot(kind='barh', color='salmon')\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Multilabel Stratified Splitting for handling the class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\r\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\r\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from datasets) (3.13.1)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/site-packages (from datasets) (2.1.2)\r\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\r\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\r\n",
            "Collecting dill<0.4.1,>=0.3.0 (from datasets)\r\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\r\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/site-packages (from datasets) (2.3.2)\r\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/site-packages (from datasets) (2.32.5)\r\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/site-packages (from datasets) (0.28.1)\r\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
            "Collecting xxhash (from datasets)\r\n",
            "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\r\n",
            "Collecting multiprocess<0.70.19 (from datasets)\r\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\r\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2024.6.1)\r\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/site-packages (from datasets) (0.34.4)\r\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/site-packages (from datasets) (25.0)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.10.8)\r\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.10.0)\r\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2024.8.30)\r\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\r\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\r\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.12.2)\r\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.9)\r\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.3)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.3)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.3.1)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.2.0)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.1)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.13.1)\r\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\r\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\r\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\r\n",
            "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\r\n",
            "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\r\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m34.6/47.7 MB\u001b[0m \u001b[31m172.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m182.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\r\n",
            "Installing collected packages: xxhash, pyarrow, dill, multiprocess, datasets\r\n",
            "Successfully installed datasets-4.4.1 dill-0.4.0 multiprocess-0.70.18 pyarrow-22.0.0 xxhash-3.6.0\r\n",
            "\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using `MultilabelStratifiedKFold`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "# X is the input (we only need index here)\n",
        "X = train_df.index.values\n",
        "# y is the multi-hot encoded label matrix\n",
        "y = train_df[labels].values\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "for train_index, val_index in mskf.split(X, y):\n",
        "  train_split = train_df.iloc[train_index]\n",
        "  val_split = train_df.iloc[val_index]\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "train_split[labels].sum().sort_values().plot(kind='barh', color='salmon')\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "toxic            13765\n",
              "severe_toxic      1435\n",
              "obscene           7605\n",
              "threat             430\n",
              "insult            7089\n",
              "identity_hate     1264\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_split[labels].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Converting to Hugging Face dataset format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
              "    num_rows: 143614\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Converting to HF dataset\n",
        "train_dataset = Dataset.from_pandas(train_split.reset_index(drop=True))\n",
        "val_dataset = Dataset.from_pandas(val_split.reset_index(drop=True))\n",
        "\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
              "        num_rows: 143614\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
              "        num_rows: 15957\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Wrapping into a Dataset Dict\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"validation\": val_dataset\n",
        "})\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  9.4333,  99.0794,  17.8842, 332.9861,  19.2587, 112.6187])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Load Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Create a tokenization and encoding function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Token and Encode Function\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"comment_text\"],\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    # Attach multilabel targets as floats\n",
        "    tokenized[\"labels\"] = [\n",
        "        [float(examples[label][i]) for label in labels]\n",
        "        for i in range(len(examples[\"comment_text\"]))\n",
        "    ]\n",
        "    return tokenized\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Tokenization/Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8713f52514441ee843e5a50a52123cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/143614 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8507c51600844078a157982ea927a5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15957 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 143614\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 15957\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tokenize the dataset\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Checking how many examples have all labels zero (non-toxic comments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b520e02b6bb45038d3f1b6018ade134",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/143614 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e05b47b5cc4795aabc39082eab2e32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/15957 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples with all 0 labels: {'train': 129015, 'validation': 14331} out of {'train': 143614, 'validation': 15957}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def all_zero(example):\n",
        "    return all(label == 0 for label in example[\"labels\"])\n",
        "\n",
        "# Count how many match the conditio\n",
        "num_all_zero = tokenized_dataset.filter(all_zero).num_rows\n",
        "print(f\"Examples with all 0 labels: {num_all_zero} out of {tokenized_dataset.num_rows}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "def model_init(trial):\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(labels),\n",
        "    problem_type='multi_label_classification'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Dynamic Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Defining Metrics Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Setup compute_metrics function\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits = eval_pred.predictions\n",
        "    labels = eval_pred.label_ids\n",
        "    logits, labels = eval_pred\n",
        "    probs = 1 / (1 + np.exp(-logits))  # sigmoid for multilabel\n",
        "    preds = (probs >= 0.4).astype(int)\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "\n",
        "    results = {\n",
        "        \"macro_f1\": f1_score(labels, preds, average='macro'),\n",
        "        \"micro_f1\": f1_score(labels, preds, average='micro'),\n",
        "        \"precision\": precision_score(labels, preds, average='macro', zero_division=0),\n",
        "        \"recall\": recall_score(labels, preds, average='macro', zero_division=0),\n",
        "        \"hamming_loss\": hamming_loss(labels, preds),\n",
        "    }\n",
        "\n",
        "    # Add ROC AUC\n",
        "    try:\n",
        "        results[\"roc_auc_macro\"] = roc_auc_score(labels, probs, average='macro')\n",
        "        results[\"roc_auc_micro\"] = roc_auc_score(labels, probs, average='micro')\n",
        "    except ValueError:\n",
        "        # Handle case where some classes have no positive samples\n",
        "        results[\"roc_auc_macro\"] = 0.0\n",
        "        results[\"roc_auc_micro\"] = 0.0\n",
        "\n",
        "    return results\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.6 Training Arguments + Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoints-toxic\",\n",
        "    fp16=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",   # <-- Save every epoch\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    save_total_limit=2,\n",
        "    disable_tqdm=False                      # Show progress bar\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = None,\n",
        "    model_init = model_init,\n",
        "    processing_class=tokenizer,\n",
        "    args = training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 04:49:12,686] A new study created in memory with name: no-name-8ac7ab5f-3c7e-4ad9-b6a9-9f8910f9e870\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6732' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6732/6732 02:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.057197</td>\n",
              "      <td>0.383623</td>\n",
              "      <td>0.732921</td>\n",
              "      <td>0.539371</td>\n",
              "      <td>0.392402</td>\n",
              "      <td>0.018947</td>\n",
              "      <td>0.954605</td>\n",
              "      <td>0.983487</td>\n",
              "      <td>9.386400</td>\n",
              "      <td>1700.014000</td>\n",
              "      <td>212.542000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.050800</td>\n",
              "      <td>0.048912</td>\n",
              "      <td>0.462581</td>\n",
              "      <td>0.751286</td>\n",
              "      <td>0.473799</td>\n",
              "      <td>0.463947</td>\n",
              "      <td>0.018174</td>\n",
              "      <td>0.967119</td>\n",
              "      <td>0.986127</td>\n",
              "      <td>9.383600</td>\n",
              "      <td>1700.512000</td>\n",
              "      <td>212.604000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.046700</td>\n",
              "      <td>0.047537</td>\n",
              "      <td>0.461332</td>\n",
              "      <td>0.751342</td>\n",
              "      <td>0.469396</td>\n",
              "      <td>0.466482</td>\n",
              "      <td>0.018383</td>\n",
              "      <td>0.972909</td>\n",
              "      <td>0.987057</td>\n",
              "      <td>9.385800</td>\n",
              "      <td>1700.126000</td>\n",
              "      <td>212.556000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 04:52:10,008] Trial 0 finished with value: 4.126901068728941 and parameters: {'learning_rate': 1.8874000584711368e-06, 'weight_decay': 0.009722648146874353, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 4.126901068728941.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13464' max='13464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13464/13464 04:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.043200</td>\n",
              "      <td>0.040316</td>\n",
              "      <td>0.552741</td>\n",
              "      <td>0.783534</td>\n",
              "      <td>0.605579</td>\n",
              "      <td>0.538594</td>\n",
              "      <td>0.015928</td>\n",
              "      <td>0.986093</td>\n",
              "      <td>0.990987</td>\n",
              "      <td>9.409700</td>\n",
              "      <td>1695.798000</td>\n",
              "      <td>212.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.036300</td>\n",
              "      <td>0.038699</td>\n",
              "      <td>0.638498</td>\n",
              "      <td>0.786532</td>\n",
              "      <td>0.704048</td>\n",
              "      <td>0.643060</td>\n",
              "      <td>0.016356</td>\n",
              "      <td>0.988646</td>\n",
              "      <td>0.992115</td>\n",
              "      <td>9.385800</td>\n",
              "      <td>1700.122000</td>\n",
              "      <td>212.555000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>0.038546</td>\n",
              "      <td>0.659303</td>\n",
              "      <td>0.789308</td>\n",
              "      <td>0.684119</td>\n",
              "      <td>0.664764</td>\n",
              "      <td>0.016054</td>\n",
              "      <td>0.989264</td>\n",
              "      <td>0.992254</td>\n",
              "      <td>9.410400</td>\n",
              "      <td>1695.672000</td>\n",
              "      <td>211.999000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 04:56:14,244] Trial 1 finished with value: 4.79506443224434 and parameters: {'learning_rate': 7.849932650648995e-06, 'weight_decay': 0.04717762016773064, 'per_device_train_batch_size': 32}. Best is trial 1 with value: 4.79506443224434.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6732' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6732/6732 02:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.041100</td>\n",
              "      <td>0.039859</td>\n",
              "      <td>0.627863</td>\n",
              "      <td>0.783907</td>\n",
              "      <td>0.729352</td>\n",
              "      <td>0.621734</td>\n",
              "      <td>0.015876</td>\n",
              "      <td>0.989236</td>\n",
              "      <td>0.991244</td>\n",
              "      <td>9.361100</td>\n",
              "      <td>1704.611000</td>\n",
              "      <td>213.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.032700</td>\n",
              "      <td>0.038669</td>\n",
              "      <td>0.678078</td>\n",
              "      <td>0.793264</td>\n",
              "      <td>0.668397</td>\n",
              "      <td>0.693119</td>\n",
              "      <td>0.015772</td>\n",
              "      <td>0.989432</td>\n",
              "      <td>0.992428</td>\n",
              "      <td>9.354300</td>\n",
              "      <td>1705.846000</td>\n",
              "      <td>213.271000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.022900</td>\n",
              "      <td>0.042353</td>\n",
              "      <td>0.693279</td>\n",
              "      <td>0.789409</td>\n",
              "      <td>0.665267</td>\n",
              "      <td>0.723916</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.989653</td>\n",
              "      <td>0.991826</td>\n",
              "      <td>9.366400</td>\n",
              "      <td>1703.650000</td>\n",
              "      <td>212.996000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 04:59:11,534] Trial 2 finished with value: 4.869551319825188 and parameters: {'learning_rate': 6.085614532354611e-05, 'weight_decay': 0.009601567168274478, 'per_device_train_batch_size': 64}. Best is trial 2 with value: 4.869551319825188.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26928' max='26928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26928/26928 06:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.040200</td>\n",
              "      <td>0.038521</td>\n",
              "      <td>0.642717</td>\n",
              "      <td>0.788874</td>\n",
              "      <td>0.703890</td>\n",
              "      <td>0.615613</td>\n",
              "      <td>0.015302</td>\n",
              "      <td>0.989544</td>\n",
              "      <td>0.992163</td>\n",
              "      <td>9.363100</td>\n",
              "      <td>1704.252000</td>\n",
              "      <td>213.072000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.034100</td>\n",
              "      <td>0.037976</td>\n",
              "      <td>0.689361</td>\n",
              "      <td>0.792891</td>\n",
              "      <td>0.690878</td>\n",
              "      <td>0.697662</td>\n",
              "      <td>0.015824</td>\n",
              "      <td>0.989388</td>\n",
              "      <td>0.992791</td>\n",
              "      <td>9.381000</td>\n",
              "      <td>1700.996000</td>\n",
              "      <td>212.664000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.026600</td>\n",
              "      <td>0.041307</td>\n",
              "      <td>0.686646</td>\n",
              "      <td>0.789445</td>\n",
              "      <td>0.662233</td>\n",
              "      <td>0.714010</td>\n",
              "      <td>0.016168</td>\n",
              "      <td>0.989816</td>\n",
              "      <td>0.992125</td>\n",
              "      <td>9.379200</td>\n",
              "      <td>1701.313000</td>\n",
              "      <td>212.704000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:06:07,730] Trial 3 finished with value: 4.85044312988956 and parameters: {'learning_rate': 1.5059319721294715e-05, 'weight_decay': 0.0453724579857859, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 4.869551319825188.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26928' max='26928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26928/26928 06:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.042700</td>\n",
              "      <td>0.040639</td>\n",
              "      <td>0.540007</td>\n",
              "      <td>0.783221</td>\n",
              "      <td>0.632370</td>\n",
              "      <td>0.513616</td>\n",
              "      <td>0.015761</td>\n",
              "      <td>0.985703</td>\n",
              "      <td>0.990779</td>\n",
              "      <td>9.417300</td>\n",
              "      <td>1694.431000</td>\n",
              "      <td>211.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.038600</td>\n",
              "      <td>0.038747</td>\n",
              "      <td>0.640623</td>\n",
              "      <td>0.789173</td>\n",
              "      <td>0.716240</td>\n",
              "      <td>0.633078</td>\n",
              "      <td>0.015782</td>\n",
              "      <td>0.988491</td>\n",
              "      <td>0.992058</td>\n",
              "      <td>9.410700</td>\n",
              "      <td>1695.614000</td>\n",
              "      <td>211.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.034200</td>\n",
              "      <td>0.039113</td>\n",
              "      <td>0.656728</td>\n",
              "      <td>0.790096</td>\n",
              "      <td>0.680980</td>\n",
              "      <td>0.658880</td>\n",
              "      <td>0.015939</td>\n",
              "      <td>0.989137</td>\n",
              "      <td>0.992152</td>\n",
              "      <td>9.390800</td>\n",
              "      <td>1699.214000</td>\n",
              "      <td>212.442000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:12:57,874] Trial 4 finished with value: 4.783911032523835 and parameters: {'learning_rate': 4.941008729034475e-06, 'weight_decay': 0.012753701749347464, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 4.869551319825188.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13464' max='13464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13464/13464 03:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.040900</td>\n",
              "      <td>0.038186</td>\n",
              "      <td>0.650862</td>\n",
              "      <td>0.789630</td>\n",
              "      <td>0.681832</td>\n",
              "      <td>0.635149</td>\n",
              "      <td>0.015510</td>\n",
              "      <td>0.989858</td>\n",
              "      <td>0.992245</td>\n",
              "      <td>9.343100</td>\n",
              "      <td>1707.900000</td>\n",
              "      <td>213.528000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.032100</td>\n",
              "      <td>0.037932</td>\n",
              "      <td>0.667627</td>\n",
              "      <td>0.791474</td>\n",
              "      <td>0.653989</td>\n",
              "      <td>0.691151</td>\n",
              "      <td>0.016043</td>\n",
              "      <td>0.990150</td>\n",
              "      <td>0.992731</td>\n",
              "      <td>9.361300</td>\n",
              "      <td>1704.579000</td>\n",
              "      <td>213.112000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.027800</td>\n",
              "      <td>0.040060</td>\n",
              "      <td>0.684306</td>\n",
              "      <td>0.790717</td>\n",
              "      <td>0.653381</td>\n",
              "      <td>0.718775</td>\n",
              "      <td>0.016106</td>\n",
              "      <td>0.990088</td>\n",
              "      <td>0.992306</td>\n",
              "      <td>9.395000</td>\n",
              "      <td>1698.459000</td>\n",
              "      <td>212.347000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:16:57,122] Trial 5 finished with value: 4.845678790044905 and parameters: {'learning_rate': 1.9784027224597626e-05, 'weight_decay': 0.03249170202920507, 'per_device_train_batch_size': 32}. Best is trial 2 with value: 4.869551319825188.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8976' max='26928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 8976/26928 02:14 < 04:29, 66.52 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.042800</td>\n",
              "      <td>0.040769</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.781411</td>\n",
              "      <td>0.628934</td>\n",
              "      <td>0.510526</td>\n",
              "      <td>0.015918</td>\n",
              "      <td>0.985543</td>\n",
              "      <td>0.990715</td>\n",
              "      <td>9.404100</td>\n",
              "      <td>1696.813000</td>\n",
              "      <td>212.142000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:19:12,484] Trial 6 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4488' max='13464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4488/13464 01:18 < 02:37, 57.07 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.042200</td>\n",
              "      <td>0.039394</td>\n",
              "      <td>0.572106</td>\n",
              "      <td>0.785663</td>\n",
              "      <td>0.589277</td>\n",
              "      <td>0.561615</td>\n",
              "      <td>0.015740</td>\n",
              "      <td>0.987542</td>\n",
              "      <td>0.991461</td>\n",
              "      <td>9.375300</td>\n",
              "      <td>1702.032000</td>\n",
              "      <td>212.794000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:20:31,557] Trial 7 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4488' max='13464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4488/13464 01:18 < 02:37, 57.14 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.045624</td>\n",
              "      <td>0.458449</td>\n",
              "      <td>0.755978</td>\n",
              "      <td>0.483248</td>\n",
              "      <td>0.453333</td>\n",
              "      <td>0.017693</td>\n",
              "      <td>0.979485</td>\n",
              "      <td>0.988260</td>\n",
              "      <td>9.383200</td>\n",
              "      <td>1700.587000</td>\n",
              "      <td>212.613000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:21:50,530] Trial 8 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2244' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2244/6732 00:57 < 01:55, 38.76 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.046300</td>\n",
              "      <td>0.043736</td>\n",
              "      <td>0.470537</td>\n",
              "      <td>0.764865</td>\n",
              "      <td>0.474576</td>\n",
              "      <td>0.473613</td>\n",
              "      <td>0.017223</td>\n",
              "      <td>0.981779</td>\n",
              "      <td>0.989429</td>\n",
              "      <td>9.397100</td>\n",
              "      <td>1698.068000</td>\n",
              "      <td>212.298000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:22:48,858] Trial 9 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6732' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6732/6732 02:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.041800</td>\n",
              "      <td>0.040244</td>\n",
              "      <td>0.609538</td>\n",
              "      <td>0.781197</td>\n",
              "      <td>0.704265</td>\n",
              "      <td>0.610106</td>\n",
              "      <td>0.016189</td>\n",
              "      <td>0.988644</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>9.411100</td>\n",
              "      <td>1695.555000</td>\n",
              "      <td>211.984000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.033000</td>\n",
              "      <td>0.039068</td>\n",
              "      <td>0.667939</td>\n",
              "      <td>0.788806</td>\n",
              "      <td>0.666846</td>\n",
              "      <td>0.676075</td>\n",
              "      <td>0.016001</td>\n",
              "      <td>0.988495</td>\n",
              "      <td>0.992155</td>\n",
              "      <td>9.411000</td>\n",
              "      <td>1695.573000</td>\n",
              "      <td>211.987000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.023100</td>\n",
              "      <td>0.042681</td>\n",
              "      <td>0.678418</td>\n",
              "      <td>0.784533</td>\n",
              "      <td>0.649238</td>\n",
              "      <td>0.710600</td>\n",
              "      <td>0.016471</td>\n",
              "      <td>0.988831</td>\n",
              "      <td>0.991664</td>\n",
              "      <td>9.403900</td>\n",
              "      <td>1696.841000</td>\n",
              "      <td>212.145000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:25:47,449] Trial 10 finished with value: 4.819754322304119 and parameters: {'learning_rate': 7.633277296702147e-05, 'weight_decay': 0.0007673031071856115, 'per_device_train_batch_size': 64}. Best is trial 2 with value: 4.869551319825188.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8976' max='26928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 8976/26928 02:16 < 04:33, 65.76 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.043900</td>\n",
              "      <td>0.042228</td>\n",
              "      <td>0.561022</td>\n",
              "      <td>0.765029</td>\n",
              "      <td>0.689161</td>\n",
              "      <td>0.550919</td>\n",
              "      <td>0.016983</td>\n",
              "      <td>0.984288</td>\n",
              "      <td>0.989473</td>\n",
              "      <td>9.423600</td>\n",
              "      <td>1693.302000</td>\n",
              "      <td>211.703000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:28:04,374] Trial 11 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6732' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6732/6732 02:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.040100</td>\n",
              "      <td>0.038471</td>\n",
              "      <td>0.650187</td>\n",
              "      <td>0.787079</td>\n",
              "      <td>0.689131</td>\n",
              "      <td>0.643652</td>\n",
              "      <td>0.015834</td>\n",
              "      <td>0.990146</td>\n",
              "      <td>0.992098</td>\n",
              "      <td>9.405600</td>\n",
              "      <td>1696.551000</td>\n",
              "      <td>212.109000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.033100</td>\n",
              "      <td>0.038016</td>\n",
              "      <td>0.686811</td>\n",
              "      <td>0.793434</td>\n",
              "      <td>0.675432</td>\n",
              "      <td>0.708705</td>\n",
              "      <td>0.015772</td>\n",
              "      <td>0.990118</td>\n",
              "      <td>0.992604</td>\n",
              "      <td>9.412300</td>\n",
              "      <td>1695.337000</td>\n",
              "      <td>211.957000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.040310</td>\n",
              "      <td>0.694843</td>\n",
              "      <td>0.789814</td>\n",
              "      <td>0.660623</td>\n",
              "      <td>0.734275</td>\n",
              "      <td>0.016294</td>\n",
              "      <td>0.990182</td>\n",
              "      <td>0.992177</td>\n",
              "      <td>9.436000</td>\n",
              "      <td>1691.082000</td>\n",
              "      <td>211.425000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:31:01,684] Trial 12 finished with value: 4.878207175126608 and parameters: {'learning_rate': 3.2719182895564304e-05, 'weight_decay': 0.023377366840031614, 'per_device_train_batch_size': 64}. Best is trial 12 with value: 4.878207175126608.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6732' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6732/6732 02:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.040100</td>\n",
              "      <td>0.038702</td>\n",
              "      <td>0.651680</td>\n",
              "      <td>0.787033</td>\n",
              "      <td>0.690292</td>\n",
              "      <td>0.643210</td>\n",
              "      <td>0.015782</td>\n",
              "      <td>0.990065</td>\n",
              "      <td>0.991942</td>\n",
              "      <td>9.463100</td>\n",
              "      <td>1686.230000</td>\n",
              "      <td>210.818000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.032900</td>\n",
              "      <td>0.038153</td>\n",
              "      <td>0.679340</td>\n",
              "      <td>0.793038</td>\n",
              "      <td>0.665213</td>\n",
              "      <td>0.704091</td>\n",
              "      <td>0.015897</td>\n",
              "      <td>0.990116</td>\n",
              "      <td>0.992508</td>\n",
              "      <td>9.450900</td>\n",
              "      <td>1688.411000</td>\n",
              "      <td>211.091000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.024700</td>\n",
              "      <td>0.040796</td>\n",
              "      <td>0.690303</td>\n",
              "      <td>0.790805</td>\n",
              "      <td>0.659580</td>\n",
              "      <td>0.725784</td>\n",
              "      <td>0.016158</td>\n",
              "      <td>0.990180</td>\n",
              "      <td>0.991923</td>\n",
              "      <td>9.481800</td>\n",
              "      <td>1682.903000</td>\n",
              "      <td>210.402000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:33:59,829] Trial 13 finished with value: 4.864732665767061 and parameters: {'learning_rate': 3.7633635970161574e-05, 'weight_decay': 0.022577078902577735, 'per_device_train_batch_size': 64}. Best is trial 12 with value: 4.878207175126608.\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6732' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6732/6732 02:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.038570</td>\n",
              "      <td>0.650089</td>\n",
              "      <td>0.786495</td>\n",
              "      <td>0.684579</td>\n",
              "      <td>0.643142</td>\n",
              "      <td>0.015918</td>\n",
              "      <td>0.989963</td>\n",
              "      <td>0.992001</td>\n",
              "      <td>9.447500</td>\n",
              "      <td>1689.011000</td>\n",
              "      <td>211.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.032900</td>\n",
              "      <td>0.038178</td>\n",
              "      <td>0.677583</td>\n",
              "      <td>0.791170</td>\n",
              "      <td>0.674222</td>\n",
              "      <td>0.695004</td>\n",
              "      <td>0.015907</td>\n",
              "      <td>0.990185</td>\n",
              "      <td>0.992552</td>\n",
              "      <td>9.437000</td>\n",
              "      <td>1690.889000</td>\n",
              "      <td>211.401000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.040538</td>\n",
              "      <td>0.689374</td>\n",
              "      <td>0.788638</td>\n",
              "      <td>0.657388</td>\n",
              "      <td>0.726514</td>\n",
              "      <td>0.016398</td>\n",
              "      <td>0.990393</td>\n",
              "      <td>0.992137</td>\n",
              "      <td>9.425800</td>\n",
              "      <td>1692.906000</td>\n",
              "      <td>211.653000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:36:57,381] Trial 14 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6732' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6732/6732 02:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.040200</td>\n",
              "      <td>0.038740</td>\n",
              "      <td>0.656813</td>\n",
              "      <td>0.786479</td>\n",
              "      <td>0.682206</td>\n",
              "      <td>0.650647</td>\n",
              "      <td>0.016033</td>\n",
              "      <td>0.989924</td>\n",
              "      <td>0.991969</td>\n",
              "      <td>9.462100</td>\n",
              "      <td>1686.420000</td>\n",
              "      <td>210.842000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.032700</td>\n",
              "      <td>0.038349</td>\n",
              "      <td>0.682263</td>\n",
              "      <td>0.792463</td>\n",
              "      <td>0.676987</td>\n",
              "      <td>0.701689</td>\n",
              "      <td>0.015876</td>\n",
              "      <td>0.990217</td>\n",
              "      <td>0.992460</td>\n",
              "      <td>9.428000</td>\n",
              "      <td>1692.507000</td>\n",
              "      <td>211.603000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.024800</td>\n",
              "      <td>0.040599</td>\n",
              "      <td>0.685880</td>\n",
              "      <td>0.789886</td>\n",
              "      <td>0.656931</td>\n",
              "      <td>0.719597</td>\n",
              "      <td>0.016231</td>\n",
              "      <td>0.990455</td>\n",
              "      <td>0.992074</td>\n",
              "      <td>9.434300</td>\n",
              "      <td>1691.381000</td>\n",
              "      <td>211.462000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:39:55,265] Trial 15 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2244' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2244/6732 00:58 < 01:57, 38.10 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.042500</td>\n",
              "      <td>0.042042</td>\n",
              "      <td>0.601303</td>\n",
              "      <td>0.776404</td>\n",
              "      <td>0.724430</td>\n",
              "      <td>0.591420</td>\n",
              "      <td>0.016430</td>\n",
              "      <td>0.985312</td>\n",
              "      <td>0.989052</td>\n",
              "      <td>9.453600</td>\n",
              "      <td>1687.928000</td>\n",
              "      <td>211.031000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:40:54,619] Trial 16 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2244' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2244/6732 00:58 < 01:57, 38.26 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.107300</td>\n",
              "      <td>0.085163</td>\n",
              "      <td>0.362587</td>\n",
              "      <td>0.692653</td>\n",
              "      <td>0.388237</td>\n",
              "      <td>0.341580</td>\n",
              "      <td>0.020012</td>\n",
              "      <td>0.930303</td>\n",
              "      <td>0.973856</td>\n",
              "      <td>9.482100</td>\n",
              "      <td>1682.855000</td>\n",
              "      <td>210.396000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:41:53,703] Trial 17 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2244' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2244/6732 00:57 < 01:56, 38.67 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.041300</td>\n",
              "      <td>0.039224</td>\n",
              "      <td>0.579659</td>\n",
              "      <td>0.786733</td>\n",
              "      <td>0.589989</td>\n",
              "      <td>0.574396</td>\n",
              "      <td>0.015782</td>\n",
              "      <td>0.987356</td>\n",
              "      <td>0.991501</td>\n",
              "      <td>9.437000</td>\n",
              "      <td>1690.894000</td>\n",
              "      <td>211.402000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:42:52,178] Trial 18 pruned. \n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2244' max='6732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2244/6732 00:58 < 01:56, 38.60 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.040700</td>\n",
              "      <td>0.039174</td>\n",
              "      <td>0.639247</td>\n",
              "      <td>0.786945</td>\n",
              "      <td>0.688481</td>\n",
              "      <td>0.640583</td>\n",
              "      <td>0.015886</td>\n",
              "      <td>0.989512</td>\n",
              "      <td>0.991524</td>\n",
              "      <td>9.450700</td>\n",
              "      <td>1688.453000</td>\n",
              "      <td>211.096000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-01 05:43:50,773] Trial 19 pruned. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.05), \n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64]),\n",
        "    }\n",
        "\n",
        "best_trials = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    hp_space=optuna_hp_space,\n",
        "    n_trials=20,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.6 Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'learning_rate': 3.2719182895564304e-05, 'weight_decay': 0.023377366840031614, 'per_device_train_batch_size': 64}\n"
          ]
        }
      ],
      "source": [
        "best_trial = best_trials  # returned from hyperparameter_search\n",
        "best_params = best_trial.hyperparameters\n",
        "print(best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoints-toxic\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=2,\n",
        "    disable_tqdm=False,\n",
        "    \n",
        "    # Updated from best trial\n",
        "    learning_rate=best_params[\"learning_rate\"],\n",
        "    weight_decay=best_params[\"weight_decay\"],\n",
        "    per_device_train_batch_size=best_params[\"per_device_train_batch_size\"],\n",
        "\n",
        "    num_train_epochs=5,\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=None,\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11220' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11220/11220 04:54, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Roc Auc Macro</th>\n",
              "      <th>Roc Auc Micro</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.040200</td>\n",
              "      <td>0.038692</td>\n",
              "      <td>0.647259</td>\n",
              "      <td>0.784970</td>\n",
              "      <td>0.680589</td>\n",
              "      <td>0.642712</td>\n",
              "      <td>0.015960</td>\n",
              "      <td>0.990085</td>\n",
              "      <td>0.991969</td>\n",
              "      <td>9.345600</td>\n",
              "      <td>1707.437000</td>\n",
              "      <td>213.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.033600</td>\n",
              "      <td>0.038525</td>\n",
              "      <td>0.679827</td>\n",
              "      <td>0.791158</td>\n",
              "      <td>0.672703</td>\n",
              "      <td>0.697391</td>\n",
              "      <td>0.016085</td>\n",
              "      <td>0.989798</td>\n",
              "      <td>0.992388</td>\n",
              "      <td>9.329200</td>\n",
              "      <td>1710.430000</td>\n",
              "      <td>213.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.025900</td>\n",
              "      <td>0.041382</td>\n",
              "      <td>0.689571</td>\n",
              "      <td>0.787217</td>\n",
              "      <td>0.652036</td>\n",
              "      <td>0.735972</td>\n",
              "      <td>0.016482</td>\n",
              "      <td>0.989978</td>\n",
              "      <td>0.991794</td>\n",
              "      <td>9.311800</td>\n",
              "      <td>1713.637000</td>\n",
              "      <td>214.245000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.019900</td>\n",
              "      <td>0.046325</td>\n",
              "      <td>0.676133</td>\n",
              "      <td>0.785219</td>\n",
              "      <td>0.652467</td>\n",
              "      <td>0.704130</td>\n",
              "      <td>0.016513</td>\n",
              "      <td>0.988693</td>\n",
              "      <td>0.990493</td>\n",
              "      <td>9.312900</td>\n",
              "      <td>1713.429000</td>\n",
              "      <td>214.219000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.015100</td>\n",
              "      <td>0.051018</td>\n",
              "      <td>0.696948</td>\n",
              "      <td>0.785763</td>\n",
              "      <td>0.667214</td>\n",
              "      <td>0.729777</td>\n",
              "      <td>0.016346</td>\n",
              "      <td>0.988467</td>\n",
              "      <td>0.990042</td>\n",
              "      <td>9.340800</td>\n",
              "      <td>1708.310000</td>\n",
              "      <td>213.579000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=11220, training_loss=0.029234252617745902, metrics={'train_runtime': 294.4591, 'train_samples_per_second': 2438.607, 'train_steps_per_second': 38.104, 'total_flos': 2.378191258381824e+16, 'train_loss': 0.029234252617745902, 'epoch': 5.0})"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "trainer.save_model(\"./best-toxic-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Saving Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ad25f501f8b4422a695339ed56c51e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "042cf8b9d81442d387218e0155e1398d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af83e511640d465a945ec56eeb5dd91e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23ab0199ae654bd59b467f4a22cde561",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...0/checkpoint-4488/model.safetensors:   1%|1         | 3.79MB /  268MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ce86474c2904dd6842954397d9b59c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...0/checkpoint-6732/model.safetensors:   1%|1         | 3.73MB /  268MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27b727d649cc4130b19e2d26db60883b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  .../run-0/checkpoint-4488/optimizer.pt:   0%|          |  604kB /  536MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1412c4a579d241e2ac13ac2892f04c4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  .../run-0/checkpoint-6732/optimizer.pt:   0%|          |  572kB /  536MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97e8d0d9a5324b72af4d519fd6bf01c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...run-1/checkpoint-13464/optimizer.pt:   0%|          |  613kB /  536MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "758a4afb74624a90a8519a644e333be7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...ic/run-1/checkpoint-13464/scaler.pt: 100%|##########| 1.38kB / 1.38kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35317824e04840f6b9e12f42af6fb2ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...checkpoints-toxic/model.safetensors:   0%|          |  574kB /  268MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2429abdbd7da40389dec1ef5ab5abcee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  .../checkpoint-13464/model.safetensors:   0%|          |  573kB /  268MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "465d467ad6dd42ea91a0df5d83d909f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...xic/run-1/checkpoint-8976/scaler.pt: 100%|##########| 1.38kB / 1.38kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a68d1c74b663420da2734503118006a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...1/checkpoint-8976/model.safetensors:   2%|1         | 4.02MB /  268MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/dipeshpandit/checkpoints-toxic/commit/8bc1def85e02de491790a7e3089e724500d63be1', commit_message='End of training', commit_description='', oid='8bc1def85e02de491790a7e3089e724500d63be1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/dipeshpandit/checkpoints-toxic', endpoint='https://huggingface.co', repo_type='model', repo_id='dipeshpandit/checkpoints-toxic'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "test_dataset = Dataset.from_pandas(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '00013b17ad220c46',\n",
              " 'comment_text': '\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"',\n",
              " 'labels': [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0]}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Add labels to test_dataset\n",
        "test_labels = test_labels_df[labels].values.astype(np.float32)\n",
        "test_dataset = test_dataset.add_column('labels', test_labels.tolist())\n",
        "test_dataset[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check how many examples are unlabelled as\n",
        "\n",
        "``` labels: [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0] ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "542cd97358224c288705f8ee6be99932",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/153164 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples with all -1 labels: 89186 out of 153164\n"
          ]
        }
      ],
      "source": [
        "def all_neg1(example):\n",
        "    return all(label == -1 for label in example[\"labels\"])\n",
        "\n",
        "# Count how many match the conditio\n",
        "num_all_neg1 = test_dataset.filter(all_neg1).num_rows\n",
        "print(f\"Examples with all -1 labels: {num_all_neg1} out of {test_dataset.num_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d7c6bedef334c57a4859f8552844f1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/153164 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'id': '0002f87b16116a7f',\n",
              " 'comment_text': '\"::: Somebody will invariably try to add Religion?  Really??  You mean, the way people have invariably kept adding \"\"Religion\"\" to the Samuel Beckett infobox?  And why do you bother bringing up the long-dead completely non-existent \"\"Influences\"\" issue?  You\\'re just flailing, making up crap on the fly. \\n ::: For comparison, the only explicit acknowledgement in the entire Amos Oz article that he is personally Jewish is in the categories!    \\n\\n \"',\n",
              " 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove the examples having all -1 labels\n",
        "def has_valid_labels(example):\n",
        "    return any(label != -1 for label in example[\"labels\"])\n",
        "\n",
        "test_dataset = test_dataset.filter(has_valid_labels)\n",
        "test_dataset[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['comment_text'], truncation=True, max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7177b723ab694aaf999982f1c41b7d69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/63978 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Per Label Threshold Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def find_optimal_thresholds(y_true, y_probs, step=0.01):\n",
        "    \"\"\"\n",
        "    Finds the best threshold per label to maximize F1 score.\n",
        "\n",
        "    Args:\n",
        "        y_true: np.array of shape (n_samples, n_labels)\n",
        "        y_probs: np.array of shape (n_samples, n_labels) - model output after sigmoid\n",
        "        step: float - step size for threshold search\n",
        "\n",
        "    Returns:\n",
        "        thresholds: list of optimal threshold per label\n",
        "    \"\"\"\n",
        "    n_labels = y_true.shape[1]\n",
        "    thresholds = []\n",
        "\n",
        "    for i in range(n_labels):\n",
        "        best_thresh = 0.5\n",
        "        best_f1 = 0.0\n",
        "        for t in np.arange(0.1, 0.9 + step, step):\n",
        "            preds = (y_probs[:, i] >= t).astype(int)\n",
        "            f1 = f1_score(y_true[:, i], preds, zero_division=0)\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresh = t\n",
        "        thresholds.append(best_thresh)\n",
        "        print(f\"Label {i}: Best threshold = {best_thresh:.2f} | F1 = {best_f1:.4f}\")\n",
        "\n",
        "    return thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label 0: Best threshold = 0.57 | F1 = 0.8312\n",
            "Label 1: Best threshold = 0.30 | F1 = 0.5564\n",
            "Label 2: Best threshold = 0.49 | F1 = 0.8383\n",
            "Label 3: Best threshold = 0.39 | F1 = 0.6275\n",
            "Label 4: Best threshold = 0.36 | F1 = 0.7636\n",
            "Label 5: Best threshold = 0.37 | F1 = 0.6179\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "# y_probs: logits from model output, apply sigmoid\n",
        "logits = trainer.predict(tokenized_dataset[\"validation\"]).predictions\n",
        "y_probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "\n",
        "# y_true: ground truth multilabels (should be 0/1 matrix)\n",
        "y_true = tokenized_dataset[\"validation\"][\"labels\"]\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Find optimal thresholds\n",
        "optimal_thresholds = find_optimal_thresholds(y_true, y_probs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "\n",
        "with open(\"optimal_thresholds.json\", \"w\") as f:\n",
        "    json.dump(optimal_thresholds, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "opt_thresholds = np.array([0.57, 0.30, 0.49, 0.39, 0.36, 0.37])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup compute metrics function with optimal thresholds per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "\n",
        "    # Use global optimal_thresholds defined outside the function\n",
        "    preds = (probs >= opt_thresholds).astype(int)\n",
        "\n",
        "    return {\n",
        "        \"f1_micro\": f1_score(labels, preds, average=\"micro\"),\n",
        "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
        "        \"precision_micro\": precision_score(labels, preds, average=\"micro\"),\n",
        "        \"recall_micro\": recall_score(labels, preds, average=\"micro\"),\n",
        "        \"precision_macro\": precision_score(labels, preds, average=\"macro\"),\n",
        "        \"recall_macro\": recall_score(labels, preds, average=\"macro\"),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_micro: 0.6668\n",
            "f1_macro: 0.6083\n",
            "precision_micro: 0.5642\n",
            "recall_micro: 0.8152\n",
            "precision_macro: 0.5264\n",
            "recall_macro: 0.7475\n"
          ]
        }
      ],
      "source": [
        "# Then evaluate\n",
        "test_results = trainer.predict(test_dataset)\n",
        "test_metrics = compute_metrics((test_results.predictions, test_results.label_ids))\n",
        "\n",
        "for k, v in test_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
